{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RDF_GAN_discriminator_pretraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiloyPurkait/GSoC-2020/blob/master/RDF_GAN_discriminator_pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D_hwa5V6g_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znwqgofyaAMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import logging\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
        "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI2mSRNbiF3O",
        "colab_type": "code",
        "outputId": "f0032ccc-b4ce-4c54-b820-03ab5ab0b197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amM8fHIvUp3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#tiny number\n",
        "_NEG_INF = -1e8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ASQmtAEJHsM",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Helper functions \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5IA2GOAUs5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def _tensorize(vocab, text):\n",
        "    \"\"\"\n",
        "    Function to convert texts into number sequences first, and then\n",
        "    add padding. Basically, tensorising them.\n",
        "    :param vocab: The vocab which is used to lookup ids\n",
        "    :type vocab: tf.tokenizer obj\n",
        "    :param text: A list of sentences or a text file\n",
        "    :type text: list\n",
        "    :return: tensorised text data\n",
        "    :rtype: tf.tensor\n",
        "    \"\"\"\n",
        "    tensor = vocab.texts_to_sequences(text)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                           padding='post')\n",
        "\n",
        "    return tensor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxjX4XQQbbLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lquXulVcbbI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def padding(tensor, max_length):\n",
        "    \"\"\"\n",
        "    Pads the given tensor to a maximum sequence length along\n",
        "    axis 1.\n",
        "    for ex -\n",
        "    let the tensor be [1,2,3,4] if th given max_length is 5\n",
        "    the tensor becomes [1,2,34,0]\n",
        "    Mostly used to pad the target sentences of the multilingual\n",
        "    model and the node_list of all models,\n",
        "\n",
        "    :param tensor:A tf tensor\n",
        "    :type tensor:tf.tensor\n",
        "    :param max_length:Dimension along axis 1, of the new tensor\n",
        "    :type max_length:int\n",
        "    :return:The padded tensor\n",
        "    :rtype:tf tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    padding = tf.constant([[0, 0], [0, max_length - tensor.shape[1]]])\n",
        "    padded_tensor = tf.pad(tensor, padding, mode='CONSTANT')\n",
        "\n",
        "    return padded_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttukSCrtbzFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from src.DataLoader imports"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aOeoCQwJRGS",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXSrGgzoUbZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LoadGatDataset(train_path, eval_path, test_path, srv_vocab,\n",
        "                   tgt_vocab, lang, num_examples=None):\n",
        "    train_ = {}\n",
        "    eval_ = {}\n",
        "    test_ = {}\n",
        "\n",
        "\n",
        "    # load the train and eval datasets\n",
        "    with open(train_path, 'rb') as f:\n",
        "        train_set = pickle.load(f)\n",
        "    with open(eval_path, 'rb') as f:\n",
        "        eval_set = pickle.load(f)\n",
        "    with open(test_path, 'rb') as f:\n",
        "        test_set = pickle.load(f)\n",
        "    with open(srv_vocab, 'rb') as f:\n",
        "        src_vocab = pickle.load(f)\n",
        "\n",
        "    train_input, train_tgt = zip(*train_set)\n",
        "    eval_input, eval_tgt = zip(*eval_set)\n",
        "    (train_nodes, train_labels, train_node1, train_node2) = zip(*train_input)\n",
        "    (eval_nodes, eval_labels, eval_node1, eval_node2) = zip(*eval_input)\n",
        "    (test_nodes, test_labels, test_node1, test_node2) = zip(*test_set)\n",
        "\n",
        "    train_[\"train_node_tensor\"] = _tensorize(src_vocab, train_nodes)\n",
        "    train_[\"train_label_tensor\"] = _tensorize(src_vocab, train_labels)\n",
        "    train_[\"train_node1_tensor\"] = _tensorize(src_vocab, train_node1)\n",
        "    train_[\"train_node2_tensor\"] = _tensorize(src_vocab, train_node2)\n",
        "\n",
        "    eval_[\"eval_node_tensor\"] = _tensorize(src_vocab, eval_nodes)\n",
        "    eval_[\"eval_label_tensor\"] = _tensorize(src_vocab, eval_labels)\n",
        "    eval_[\"eval_node1_tensor\"] = _tensorize(src_vocab, eval_node1)\n",
        "    eval_[\"eval_node2_tensor\"] = _tensorize(src_vocab, eval_node2)\n",
        "\n",
        "    test_[\"test_node_tensor\"] = _tensorize(src_vocab, test_nodes)\n",
        "    test_[\"test_label_tensor\"] = _tensorize(src_vocab, test_labels)\n",
        "    test_[\"test_node1_tensor\"] = _tensorize(src_vocab, test_node1)\n",
        "    test_[\"test_node2_tensor\"] = _tensorize(src_vocab, test_node1)\n",
        "\n",
        "\n",
        "    train_tgt_tensor = src_vocab.texts_to_sequences(train_tgt)\n",
        "    train_[\"train_tgt_tensor\"] = tf.keras.preprocessing.sequence.pad_sequences(train_tgt_tensor, padding='post')\n",
        "    eval_tgt_tensor = src_vocab.texts_to_sequences(eval_tgt)\n",
        "    eval_[\"eval_tgt_tensor\"] = tf.keras.preprocessing.sequence.pad_sequences(eval_tgt_tensor, padding='post')\n",
        "    target_vocab = src_vocab\n",
        "\n",
        "    return (train_, eval_, test_, src_vocab, target_vocab, max_length(train_tgt_tensor))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vcoOnT3UPor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetGATDataset(train_path, eval_path,\n",
        "                  test_path, src_vocab,\n",
        "                  tgt_vocab, lang,\n",
        "                  set=None):\n",
        "  \n",
        "\n",
        "    (train, eval, test, src_vocab, tgt_vocab, max_length_targ) = LoadGatDataset(train_path,\n",
        "                                                                                eval_path,\n",
        "                                                                                test_path, src_vocab,\n",
        "                                                                                tgt_vocab, lang)\n",
        "    node_tensor = padding(train[\"train_node_tensor\"], 16)\n",
        "    label_tensor = padding(train[\"train_label_tensor\"], 16)\n",
        "    node1_tensor = padding(train[\"train_node1_tensor\"], 16)\n",
        "    node2_tensor = padding(train[\"train_node2_tensor\"], 16)\n",
        "\n",
        "    eval_nodes = padding(eval[\"eval_node_tensor\"], 16)\n",
        "    eval_labels = padding(eval[\"eval_label_tensor\"], 16)\n",
        "    eval_node1 = padding(eval[\"eval_node1_tensor\"], 16)\n",
        "    eval_node2 = padding(eval[\"eval_node2_tensor\"], 16)\n",
        "\n",
        "    test_nodes = padding(test[\"test_node_tensor\"], 16)\n",
        "    test_labels = padding(test[\"test_label_tensor\"], 16)\n",
        "    test_node1 = padding(test[\"test_node1_tensor\"], 16)\n",
        "    test_node2 = padding(test[\"test_node2_tensor\"], 16)\n",
        "\n",
        "    print('\\nTrain Tensor shapes (nodes, labels, node1, node2, target) : ')\n",
        "    print(node_tensor.shape, label_tensor.shape, node1_tensor.shape, node2_tensor.shape, train[\"train_tgt_tensor\"].shape)\n",
        "    print('\\nEval Tensor shapes (nodes, labes, node1, node2) : ')\n",
        "    print(eval_nodes.shape, eval_labels.shape, eval_node1.shape, eval_node2.shape, eval[\"eval_tgt_tensor\"].shape)\n",
        "    print('\\nTest Tensor shapes (nodes, labes, node1, node2) : ')\n",
        "    print(test_nodes.shape, test_labels.shape, test_node1.shape, test_node2.shape)\n",
        "\n",
        "    TRAIN_BUFFER_SIZE = len(train[\"train_tgt_tensor\"])\n",
        "    EVAL_BUFFER_SIZE = len(eval[\"eval_tgt_tensor\"])\n",
        "    BATCH_SIZE = batch_size\n",
        "    steps_per_epoch = len(train[\"train_tgt_tensor\"]) // BATCH_SIZE\n",
        "    src_vocab_size = len(src_vocab.word_index) + 1\n",
        "\n",
        "    tgt_vocab_size = len(tgt_vocab.word_index) + 1\n",
        "\n",
        "    dataset_size = train[\"train_tgt_tensor\"].shape[0]\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((node_tensor, label_tensor,\n",
        "                                                  node1_tensor, node2_tensor, train[\"train_tgt_tensor\"])).shuffle(TRAIN_BUFFER_SIZE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "    eval_set = tf.data.Dataset.from_tensor_slices((eval_nodes, eval_labels,\n",
        "                                                   eval_node1, eval_node2, eval[\"eval_tgt_tensor\"])).shuffle(EVAL_BUFFER_SIZE)\n",
        "    eval_set = eval_set.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "    test_set = tf.data.Dataset.from_tensor_slices((test_nodes, test_labels,\n",
        "                                                   test_node1, test_node2))\n",
        "    test_set = test_set.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "    if set == None:\n",
        "        return (dataset, eval_set, test_set, TRAIN_BUFFER_SIZE, BATCH_SIZE, steps_per_epoch,\n",
        "                src_vocab_size, src_vocab, tgt_vocab_size, tgt_vocab,\n",
        "                max_length_targ, dataset_size)\n",
        "    elif set == 'test':\n",
        "        return (test_set, TRAIN_BUFFER_SIZE, BATCH_SIZE, steps_per_epoch,\n",
        "                src_vocab_size, src_vocab, tgt_vocab_size, tgt_vocab)\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Z6uW98JZHx",
        "colab_type": "text"
      },
      "source": [
        "## Load processed Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27UyhuV0gJYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "train_path = '/content/gdrive/My Drive/data/reif_train'\n",
        "eval_path = '/content/gdrive/My Drive/data/reif_eval'\n",
        "test_path = '/content/gdrive/My Drive/data/reif_test'\n",
        "src_vocab = '/content/gdrive/My Drive/data/reif_src_vocab'\n",
        "tgt_vocab =  '/content/gdrive/My Drive/data/train_vocab.model'\n",
        "\n",
        "\n",
        "lang = 'eng'\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k68L7MMxdqq0",
        "colab_type": "code",
        "outputId": "cf8c1286-78f0-4a73-87fa-67f3db6a4b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "(dataset, eval_set, test_set, BUFFER_SIZE, BATCH_SIZE, steps_per_epoch,\n",
        "     src_vocab_size, src_vocab, tgt_vocab_size, tgt_vocab, max_length_targ, dataset_size) = GetGATDataset(train_path, eval_path,\n",
        "                                                                                                     test_path, src_vocab,\n",
        "                                                                                                      tgt_vocab, lang)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Tensor shapes (nodes, labels, node1, node2, target) : \n",
            "(34352, 16) (34352, 16) (34352, 16) (34352, 16) (34352, 82)\n",
            "\n",
            "Eval Tensor shapes (nodes, labes, node1, node2) : \n",
            "(4316, 16) (4316, 16) (4316, 16) (4316, 16) (4316, 70)\n",
            "\n",
            "Test Tensor shapes (nodes, labes, node1, node2) : \n",
            "(4224, 16) (4224, 16) (4224, 16) (4224, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGNqXHDqJnCS",
        "colab_type": "text"
      },
      "source": [
        "## Probe the loaded dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abUI0uFMlYlY",
        "colab_type": "code",
        "outputId": "8728ced5-31e6-4ffe-9a04-cb08516c0c25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tgt_vocab_size, src_vocab_size"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10248, 10248)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfPun4cgoGxT",
        "colab_type": "code",
        "outputId": "f7e76045-dd4d-44d9-9699-7921549ec7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " dataset_size, BUFFER_SIZE, BATCH_SIZE, steps_per_epoch"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34352, 34352, 64, 536)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDYoDAVsJskI",
        "colab_type": "text"
      },
      "source": [
        "## Make example input and target batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HT4aIZEtmZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example inputs and target batch for testing\n",
        "\n",
        "nodes_, labels_, node1_, node2_, target_ = next(iter(dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Qew4p4uaBx",
        "colab_type": "code",
        "outputId": "99443533-1d6b-4664-ba7e-91936b8e13fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        " def convert_to_string(target_, n):\n",
        "    '''\n",
        "    args:\n",
        "      target_ : target tensor batch\n",
        "      n = nth element in batch \n",
        "\n",
        "    usage:\n",
        "      Takes in a tensor of (batch_size, vocab_size) and\n",
        "      converts a batch instance into its string equivalent\n",
        "    '''\n",
        "    sequence = [tf.reduce_sum(i).numpy() for i in target_[n]]\n",
        "    text = ' '.join([src_vocab.index_word[i] if i!=0 else '<pad>' for i in sequence])\n",
        "    print(text)\n",
        "\n",
        "convert_to_string(target_, 1)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> the comic character , auron s full name is lambien . <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBWSiLCQJ_21",
        "colab_type": "text"
      },
      "source": [
        "# Implement Encoder Module Layers:\n",
        "To assemble the encoder modules, we must first define the following layers:\n",
        "- Shared Embedding Layer\n",
        "- Graph Attention Layer\n",
        "- Feed Forward Layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-1kqlQDJzn_",
        "colab_type": "text"
      },
      "source": [
        "### Define Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgKqm77ruBaS",
        "colab_type": "text"
      },
      "source": [
        "# Implement LSTM model as Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLEOkDm5uAso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda,  Concatenate, LSTM\n",
        " \n",
        "from tensorflow.keras.layers import Dense, Embedding,Activation, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def Discriminator(V, E, H=64, dropout=0.1):\n",
        "    '''\n",
        "    Disciriminator model.\n",
        "    # Arguments:\n",
        "        V: int, Vocabrary size\n",
        "        E: int, Embedding size\n",
        "        H: int, LSTM hidden size\n",
        "        dropout: float\n",
        "    # Returns:\n",
        "        discriminator: keras model\n",
        "            input: word ids, shape = (B, T)\n",
        "            output: probability of true data or not, shape = (B, 1)\n",
        "    '''\n",
        "\n",
        "    def Highway(x, num_layers=1, activation='relu', name_prefix=''):\n",
        "\n",
        "      '''\n",
        "      Layer wrapper function for Highway network\n",
        "      # Arguments:\n",
        "          x: tensor, shape = (B, input_size)\n",
        "      # Optional Arguments:\n",
        "          num_layers: int, dafault is 1, the number of Highway network layers\n",
        "          activation: keras activation, default is 'relu'\n",
        "          name_prefix: str, default is '', layer name prefix\n",
        "      # Returns:\n",
        "          out: tensor, shape = (B, input_size)\n",
        "      '''\n",
        "      input_size = K.int_shape(x)[1]\n",
        "      for i in range(num_layers):\n",
        "          gate_ratio_name = '{}Highway/Gate_ratio_{}'.format(name_prefix, i)\n",
        "          fc_name = '{}Highway/FC_{}'.format(name_prefix, i)\n",
        "          gate_name = '{}Highway/Gate_{}'.format(name_prefix, i)\n",
        "\n",
        "          gate_ratio = Dense(input_size, activation='sigmoid', name=gate_ratio_name)(x)\n",
        "          fc = Dense(input_size, activation=activation, name=fc_name)(x)\n",
        "          x = Lambda(lambda args: args[0] * args[2] + args[1] * (1 - args[2]), name=gate_name)([fc, x, gate_ratio])\n",
        "      return x\n",
        "\n",
        "\n",
        "    input_ = Input(shape=(None,), dtype='int32', name='Input')   # (B, T)\n",
        "    out = Embedding(V, E, mask_zero=True, name='Embedding')(input_)  # (B, T, E)\n",
        "    out = LSTM(H)(out)\n",
        "    out = Highway(out, num_layers=1)\n",
        "    out = Dropout(dropout, name='Dropout')(out)\n",
        "    out = Dense(1, activation='sigmoid', name='FC')(out)\n",
        "\n",
        "    discriminator = Model(input_, out)\n",
        "    return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I1Katv0dRpH",
        "colab_type": "text"
      },
      "source": [
        "# Define generator loss, Agent and Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX6HOehAcofg",
        "colab_type": "text"
      },
      "source": [
        "## Define Agent class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_wI4Z03c2cd",
        "colab_type": "text"
      },
      "source": [
        "## Initialize training variables and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMCFj5k-lSLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10248\n",
        "embedding_size = 16\n",
        "BATCH_SIZE = batch_size\n",
        "epochs = 10\n",
        "step=0\n",
        "steps = epochs * steps_per_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_LJh7w2Wf_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Generator checkpoint/not necessary for discriminator##################\n",
        "\n",
        "\n",
        "checkpoint_dir = './gdrive/My Drive/RDF_GAN/training_checkpoints'\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdPBeclc5ift",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = Discriminator(vocab_size,\n",
        "                              embedding_size,\n",
        "                              H=64, dropout=0.1)\n",
        "discriminator.compile('adam', 'binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2PZbsKjiM0H",
        "colab_type": "text"
      },
      "source": [
        "## Define function to generate discriminator data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8k_nyQpiBRs",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKXz_ztSgsET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_progress(path):\n",
        "\n",
        "  discriminator.save_weights(path+'/discriminator_weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BtuM6wLRyS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(real, targ_shape):\n",
        "\n",
        "    #real_bool = np.array(real)[:,:]==0\n",
        "    #real_len = [len(i) for i in real_bool]\n",
        "    fake = np.random.randint(0, 10248, size=(batch_size, targ_shape))\n",
        "    \n",
        "    for ind, i in enumerate(fake):\n",
        "      i[random.randint(0, 72):] = 0\n",
        "\n",
        "    fake = np.concatenate([fake, np.ones((batch_size,1), dtype=np.int32)], axis=-1)\n",
        "\n",
        "    disc_data = np.vstack([real, list(fake)])\n",
        "    \n",
        "    X, y = disc_data[:,:-1], disc_data[:,-1]\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xaj9bB98bjow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiEEXXBihUhA",
        "colab_type": "text"
      },
      "source": [
        "## Define training step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZEfz_ScMait",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Training step \n",
        "\n",
        "def train_step(discriminator, targ):\n",
        "\n",
        "\n",
        "  # Store the target sequences as a negative class instance \n",
        "  disc_real = [[np.concatenate([np.array(y), np.array([1])])] for y in targ]\n",
        "  \n",
        "\n",
        "\n",
        "  # Get X_train, y_train for discriminator\n",
        "  d_x, d_y = data_generator(disc_real[0], targ.shape[1])\n",
        "\n",
        "  # Train Discriminator\n",
        "  print('Discriminator loss :')\n",
        "  discriminator.fit(d_x, d_y, batch_size=BATCH_SIZE, epochs=1)\n",
        "\n",
        "\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoyVwjYcc8my",
        "colab_type": "text"
      },
      "source": [
        "## Execute training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNpI_CvsqT50",
        "colab_type": "code",
        "outputId": "98e46112-6d93-448c-a9c5-45229e4fc463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training algorithm\n",
        "\n",
        "\n",
        "\n",
        "step=0\n",
        "steps = epochs * steps_per_epoch\n",
        "epochs=5\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    with tqdm(total=(34352 // batch_size)) as pbar:\n",
        "        for (batch, (node_, label_, node1_, node2_, targ_)) in tqdm(enumerate(dataset)):\n",
        "            start = time.time()\n",
        "            step += 1\n",
        "\n",
        "            # Store the target sequences as a negative class instance \n",
        "            disc_real = [[np.concatenate([np.array(y), np.array([1])])] for y in targ_]\n",
        "\n",
        "            # Get X_train, y_train for discriminator\n",
        "            d_x, d_y = data_generator(disc_real[0], targ_.shape[1])\n",
        "\n",
        "            # Train Discriminator\n",
        "            print('Discriminator loss :')\n",
        "            discriminator.fit(d_x, d_y, batch_size=BATCH_SIZE, epochs=1)\n",
        "\n",
        "            save_progress(checkpoint_dir)\n",
        "\n",
        "            print('Epoch {} Batch {} '.format(epoch, batch))\n",
        "\n",
        "            print('Time {} \\n'.format(time.time() - start))\n",
        "            pbar.update(1)\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/536 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.6932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 1/536 [00:04<36:31,  4.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1it [00:04,  4.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 0 \n",
            "Time 4.038578748703003 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 2/536 [00:04<26:10,  2.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2it [00:04,  2.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 1 \n",
            "Time 0.2341020107269287 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|          | 3/536 [00:04<18:59,  2.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3it [00:04,  2.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 2 \n",
            "Time 0.25983119010925293 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|          | 4/536 [00:04<13:54,  1.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4it [00:04,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 3 \n",
            "Time 0.23514413833618164 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|          | 5/536 [00:05<10:22,  1.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5it [00:05,  1.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 4 \n",
            "Time 0.2392139434814453 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|          | 6/536 [00:05<07:58,  1.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6it [00:05,  1.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 5 \n",
            "Time 0.26395082473754883 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.6152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|▏         | 7/536 [00:05<06:17,  1.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "7it [00:05,  1.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 6 \n",
            "Time 0.2641596794128418 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|▏         | 8/536 [00:05<05:04,  1.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "8it [00:05,  1.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 7 \n",
            "Time 0.2511875629425049 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 9/536 [00:06<04:15,  2.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "9it [00:06,  2.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 8 \n",
            "Time 0.2575206756591797 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 10/536 [00:06<03:38,  2.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "10it [00:06,  2.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 9 \n",
            "Time 0.24759674072265625 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 11/536 [00:06<03:16,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11it [00:06,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 10 \n",
            "Time 0.2636399269104004 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 12/536 [00:06<03:00,  2.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "12it [00:06,  2.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 11 \n",
            "Time 0.27327489852905273 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 13/536 [00:07<02:46,  3.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "13it [00:07,  3.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 12 \n",
            "Time 0.2399303913116455 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 14/536 [00:07<02:36,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "14it [00:07,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 13 \n",
            "Time 0.24749398231506348 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 15/536 [00:07<02:33,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "15it [00:07,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 14 \n",
            "Time 0.27447938919067383 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.0542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 16/536 [00:08<02:25,  3.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "16it [00:08,  3.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 15 \n",
            "Time 0.24262642860412598 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 17/536 [00:08<02:24,  3.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "17it [00:08,  3.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 16 \n",
            "Time 0.26709771156311035 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 18/536 [00:08<02:19,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "18it [00:08,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 17 \n",
            "Time 0.23685693740844727 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▎         | 19/536 [00:08<02:16,  3.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "19it [00:08,  3.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 18 \n",
            "Time 0.24318695068359375 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▎         | 20/536 [00:09<02:19,  3.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "20it [00:09,  3.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 19 \n",
            "Time 0.27703166007995605 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▍         | 21/536 [00:09<02:15,  3.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "21it [00:09,  3.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 20 \n",
            "Time 0.23818278312683105 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▍         | 22/536 [00:09<02:14,  3.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "22it [00:09,  3.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 21 \n",
            "Time 0.24439549446105957 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▍         | 23/536 [00:09<02:17,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "23it [00:09,  3.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 22 \n",
            "Time 0.27936768531799316 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▍         | 24/536 [00:10<02:15,  3.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "24it [00:10,  3.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 23 \n",
            "Time 0.24743413925170898 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▍         | 25/536 [00:10<02:16,  3.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "25it [00:10,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 24 \n",
            "Time 0.2668635845184326 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▍         | 26/536 [00:10<02:17,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26it [00:10,  3.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 25 \n",
            "Time 0.26201629638671875 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 27/536 [00:10<02:16,  3.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "27it [00:10,  3.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 26 \n",
            "Time 0.25745654106140137 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 28/536 [00:11<02:15,  3.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "28it [00:11,  3.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 27 \n",
            "Time 0.2617497444152832 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 29/536 [00:11<02:13,  3.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "29it [00:11,  3.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 28 \n",
            "Time 0.24330568313598633 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  6%|▌         | 30/536 [00:11<02:14,  3.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "30it [00:11,  3.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 29 \n",
            "Time 0.2615549564361572 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  6%|▌         | 31/536 [00:12<02:16,  3.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "31it [00:12,  3.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 30 \n",
            "Time 0.27112674713134766 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  6%|▌         | 32/536 [00:12<02:16,  3.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "32it [00:12,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 31 \n",
            "Time 0.2580723762512207 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  6%|▌         | 33/536 [00:12<02:14,  3.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "33it [00:12,  3.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 32 \n",
            "Time 0.25144314765930176 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  6%|▋         | 34/536 [00:12<02:16,  3.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "34it [00:12,  3.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 33 \n",
            "Time 0.2746603488922119 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 35/536 [00:13<02:12,  3.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "35it [00:13,  3.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 34 \n",
            "Time 0.23291850090026855 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.0411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 36/536 [00:13<02:13,  3.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "36it [00:13,  3.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 35 \n",
            "Time 0.26586365699768066 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 37/536 [00:13<02:14,  3.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "37it [00:13,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 36 \n",
            "Time 0.267589807510376 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 38/536 [00:13<02:18,  3.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "38it [00:13,  3.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 37 \n",
            "Time 0.2893216609954834 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 39/536 [00:14<02:18,  3.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "39it [00:14,  3.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 38 \n",
            "Time 0.2679264545440674 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 40/536 [00:14<02:17,  3.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "40it [00:14,  3.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 39 \n",
            "Time 0.2710084915161133 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 41/536 [00:14<02:20,  3.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "41it [00:14,  3.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 40 \n",
            "Time 0.28675103187561035 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 42/536 [00:15<02:20,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "42it [00:15,  3.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 41 \n",
            "Time 0.2783365249633789 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 43/536 [00:15<02:16,  3.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "43it [00:15,  3.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 42 \n",
            "Time 0.2532172203063965 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 44/536 [00:15<02:21,  3.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "44it [00:15,  3.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 43 \n",
            "Time 0.2987973690032959 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 45/536 [00:15<02:18,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "45it [00:15,  3.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 44 \n",
            "Time 0.26276373863220215 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  9%|▊         | 46/536 [00:16<02:18,  3.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "46it [00:16,  3.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 45 \n",
            "Time 0.27648329734802246 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  9%|▉         | 47/536 [00:16<02:17,  3.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "47it [00:16,  3.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 46 \n",
            "Time 0.2670462131500244 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  9%|▉         | 48/536 [00:16<02:18,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "48it [00:16,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 47 \n",
            "Time 0.2869687080383301 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  9%|▉         | 49/536 [00:17<02:19,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "49it [00:17,  3.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 48 \n",
            "Time 0.28061842918395996 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  9%|▉         | 50/536 [00:17<02:16,  3.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "50it [00:17,  3.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 49 \n",
            "Time 0.2569878101348877 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|▉         | 51/536 [00:17<02:15,  3.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "51it [00:17,  3.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 50 \n",
            "Time 0.26757121086120605 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.0236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|▉         | 52/536 [00:17<02:20,  3.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52it [00:17,  3.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 51 \n",
            "Time 0.3051605224609375 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.0260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|▉         | 53/536 [00:18<02:18,  3.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "53it [00:18,  3.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 52 \n",
            "Time 0.27309322357177734 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.0144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 54/536 [00:18<02:18,  3.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "54it [00:18,  3.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 53 \n",
            "Time 0.2796905040740967 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 55/536 [00:18<02:16,  3.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "55it [00:18,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 54 \n",
            "Time 0.2673799991607666 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 56/536 [00:19<02:21,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "56it [00:19,  3.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 55 \n",
            "Time 0.30649542808532715 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.0118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 11%|█         | 57/536 [00:19<02:18,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "57it [00:19,  3.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 56 \n",
            "Time 0.2664310932159424 \n",
            "\n",
            "Discriminator loss :\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 11%|█         | 57/536 [00:19<02:44,  2.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SaveV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m         tld.op_callbacks, prefix, tensor_names, shape_and_slices, tensors)\n\u001b[0m\u001b[1;32m   1703\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-4d7f833317cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0msave_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {} Batch {} '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-141-21725b041425>\u001b[0m in \u001b[0;36msave_progress\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/discriminator_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[1;32m   1165\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[1;32m   1166\u001b[0m             % (optimizer,))\n\u001b[0;32m-> 1167\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m       \u001b[0;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1187\u001b[0;31m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[1;32m   1188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1134\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         return save_v2_eager_fallback(\n\u001b[1;32m   1707\u001b[0m             \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m   1709\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1728\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1730\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1731\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FQ0OqXhAaOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOS = tgt_vocab.word_index['<start>']\n",
        "EOS = tgt_vocab.word_index['<end>']\n",
        "\n",
        "BOS, EOS\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBU_tOgEVcQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}